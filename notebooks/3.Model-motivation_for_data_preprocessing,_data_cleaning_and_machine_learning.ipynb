{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95df5577",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db21b98",
   "metadata": {},
   "source": [
    "Previously we have take an in-depth look at our data, cleaned it and have a rough understanding of what features might be important to predict the sales price.\n",
    "\n",
    "Now, we will build machine learning models to conduct our prediction.\n",
    "\n",
    "Before we can fit the data into the model, we will have to do some data preprocessing steps.\n",
    "\n",
    "In this notebook, we will provide some motivations to why data preprocessing and data cleaning are important and what is machine learning all about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87923d9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.023320Z",
     "start_time": "2021-07-18T05:05:55.195551Z"
    }
   },
   "outputs": [],
   "source": [
    "###########\n",
    "# imports #\n",
    "###########\n",
    "import pickle # load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##########\n",
    "# models #\n",
    "##########\n",
    "# linear models\n",
    "from sklearn.linear_model import (\n",
    "    # Ordinary least squares Linear Regression\n",
    "    LinearRegression\n",
    ")\n",
    "# tree model\n",
    "from sklearn.tree import (\n",
    "    # A decision tree regressor\n",
    "    DecisionTreeRegressor,\n",
    "    # Plot a decision tree\n",
    "    plot_tree\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d90d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.133503Z",
     "start_time": "2021-07-18T05:05:57.025944Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the cleaned data\n",
    "with open(\"../data/hdb_final\", \"rb\") as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61238f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.182792Z",
     "start_time": "2021-07-18T05:05:57.135010Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c406e6cd",
   "metadata": {},
   "source": [
    "# Take a step back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7014b616",
   "metadata": {},
   "source": [
    "## what is machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0c7ad",
   "metadata": {},
   "source": [
    "A machine learning model in the simplest sense is about predicting an outcome (y) with an input data (X). There is nothing fancy or too intelligent about the behaviour. Therefore, it is very important for us to fit the model with meaningful data points instead of random noise.\n",
    "\n",
    "Let's illustrate the importance of data cleaning with a simple function: $y = 10 + 5*x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b375c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.189330Z",
     "start_time": "2021-07-18T05:05:57.186107Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating ground truth\n",
    "_total_sample = 1000  # let's create 1000 samples\n",
    "X = np.random.random(_total_sample) * 10\n",
    "X = X.reshape(-1, 1)\n",
    "y = 10 + 5 * X\n",
    "y = y.reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843aa6b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.327879Z",
     "start_time": "2021-07-18T05:05:57.191004Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(X, y)\n",
    "plt.title(\"y = 10 + 5x\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17e549",
   "metadata": {},
   "source": [
    "Now, when x = 0, y = 10; x = 1, X = 10, y = 10 + 5 * 10 = 60. Our data is generated properly.\n",
    "\n",
    "We can fit a simple linear regression to capture this relationship.\n",
    "\n",
    "[sklearn](https://scikit-learn.org/stable/modules/classes.html) provides a very easy to use high level API for machine learning problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dad91d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.337694Z",
     "start_time": "2021-07-18T05:05:57.329807Z"
    }
   },
   "outputs": [],
   "source": [
    "# initiate a linear regression model\n",
    "lm = LinearRegression()\n",
    "# fit the data\n",
    "lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf2f10",
   "metadata": {},
   "source": [
    "We have built a \"machine learning model\" with 2 lines of code (provided we have very clean data). Changing the model is as simple as calling another function.\n",
    "\n",
    "Let's fit a random forest model next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d835df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.345290Z",
     "start_time": "2021-07-18T05:05:57.339215Z"
    }
   },
   "outputs": [],
   "source": [
    "# initiate a tree regressor model\n",
    "tree = DecisionTreeRegressor(\n",
    "    # set seed to reproduce the result\n",
    "    random_state=123,\n",
    "    # The maximum depth of the tree\n",
    "    max_depth=3\n",
    ")\n",
    "# fit the data\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a34c40",
   "metadata": {},
   "source": [
    "To conduct prediction it is as simple as calling a single line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36480ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.351281Z",
     "start_time": "2021-07-18T05:05:57.347421Z"
    }
   },
   "outputs": [],
   "source": [
    "# let Xi = 6, we expect the ground truth to be 10 + 5 * 6 = 40\n",
    "_sample = [[6]]\n",
    "print(f\"Linear regression prediction: {lm.predict(_sample)}\")\n",
    "print(f\"Tree regressor prediction: {tree.predict(_sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd95f79",
   "metadata": {},
   "source": [
    "Both linear regression and tree model does very good prediction with this simple data. But what is really happening behind those model?\n",
    "\n",
    "To investigate how the model arrive achieve those prediction is called `explainability`. Some models are easy to interpret (e.g. linear regression) while some are not possible to interpret fully (e.g. neural network). As a data scientist we have to understand the trade off between `explainability` and `predictive power`. There might be use cases when we care more about HOW the model predict the outcome instead of HOW GOOD the model is at predicting.\n",
    "\n",
    "For example, if we were to build a model deciding which patient to receive medical care first, we might want a humane reason (ethnical reasons) instead of trusting fully on the model. On the other hand, if we are predicting stock market performance, we might not be concern with why our model predict the stock will go up, as long as we are earning a profit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250d883",
   "metadata": {},
   "source": [
    "**linear regression explainability**\n",
    "\n",
    "in a simple sense, linear regression is about finding a best fit line that minimise an error function\n",
    "\n",
    "Therefore, how linear regression predicts the outcome is basically rely on (simple linear regression case)\n",
    "\n",
    "$\\hat{y} = \\hat{b_0} + \\hat{b_1} * x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ba21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.356971Z",
     "start_time": "2021-07-18T05:05:57.352833Z"
    }
   },
   "outputs": [],
   "source": [
    "lm.intercept_, lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83182b18",
   "metadata": {},
   "source": [
    "In our case, $b_0 = 10$, and $b_1 = 5$. The estimated coefficients are highly accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c004b1",
   "metadata": {},
   "source": [
    "**decision tree explainability**\n",
    "\n",
    "In a simple sense, decision tree works by splitting the data based on a information criteria\n",
    "\n",
    "therefore, what the tree model is doing is basically grouping data that are similar to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3976b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.879512Z",
     "start_time": "2021-07-18T05:05:57.362162Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_tree(tree)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd93b03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.886598Z",
     "start_time": "2021-07-18T05:05:57.881279Z"
    }
   },
   "outputs": [],
   "source": [
    "# to illustrate our point, any data that is between 4.976 to 6.217\n",
    "# will give us the same prediction result of 38.11675092 (which is our sample prediction result)\n",
    "tree.predict(np.arange(4.976, 6.217, step=0.1).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87d43f",
   "metadata": {},
   "source": [
    "## why is data preprocessing is important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b30f38",
   "metadata": {},
   "source": [
    "Now, imagine instead of having numeric data, we have categorical data. The model will not be able to calculate any mathematically result from the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062b63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.892368Z",
     "start_time": "2021-07-18T05:05:57.887984Z"
    }
   },
   "outputs": [],
   "source": [
    "# sklearn will attempt to convert string object into numeric data,\n",
    "# we prevent this behaviour by adding additional non numeric text\n",
    "X_categorical = np.char.add(\"X = \", X.astype(\"str\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77841085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.899793Z",
     "start_time": "2021-07-18T05:05:57.894326Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    lm.fit(X_categorical, y)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27917c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.906760Z",
     "start_time": "2021-07-18T05:05:57.901944Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tree.fit(X_categorical, y)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a41b7",
   "metadata": {},
   "source": [
    "Therefore, it is important to find a numeric representation of our data in order to train any machine learning (and deep learning) model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ce43a",
   "metadata": {},
   "source": [
    "## why is data cleaning is important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7de98c",
   "metadata": {},
   "source": [
    "Previously we have seen how both linear regression and tree model work relatively well in our simple case.\n",
    "\n",
    "Now, what if we add some noise to the data? (adding data that does not follow the relationship y = 10 + 5 * X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412e9b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:57.914227Z",
     "start_time": "2021-07-18T05:05:57.908331Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_noise(x_clean, y_clean, percent_noise):\n",
    "    \"\"\"Add a certain percentage of noisy data.\"\"\"\n",
    "    data = np.concatenate([x_clean, y_clean.reshape(-1, 1)], axis=1)\n",
    "    n_noise = round(percent_noise * data.shape[0])\n",
    "    noise_x = np.random.random(n_noise).reshape(-1, 1)\n",
    "    noise_y = np.random.random(n_noise).reshape(-1, 1)\n",
    "    # scale the noise to a random integer\n",
    "    noise_x *= np.random.randint(0, 100, size=(n_noise, 1))\n",
    "    noise_y *= np.random.randint(0, 100, size=(n_noise, 1))\n",
    "    noise = np.concatenate([noise_x, noise_y], axis=1)\n",
    "    data_noise = np.concatenate([data, noise], axis=0)\n",
    "    np.random.shuffle(data)\n",
    "    X_noise, y_noise = data_noise[:, 0], data_noise[:, 1]\n",
    "    return X_noise.reshape(-1, 1), y_noise.reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63c97b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:58.052438Z",
     "start_time": "2021-07-18T05:05:57.915715Z"
    }
   },
   "outputs": [],
   "source": [
    "# now if we add 10% noise to the data, \n",
    "# we see that most of the data points still follow the relationship we expected\n",
    "# but there are some random noise in our data\n",
    "X_noise, y_noise = add_noise(X, y, .1)\n",
    "lm.fit(X_noise, y_noise), tree.fit(X_noise, y_noise)\n",
    "plt.scatter(X_noise, y_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0269bea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:58.059826Z",
     "start_time": "2021-07-18T05:05:58.054842Z"
    }
   },
   "outputs": [],
   "source": [
    "# let Xi = 6, we expect the ground truth to be 10 + 5 * 6 = 40\n",
    "_sample = [[6]]\n",
    "print(f\"Linear regression prediction: {lm.predict(_sample)}\")\n",
    "print(f\"Tree regressor prediction: {tree.predict(_sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76235e03",
   "metadata": {},
   "source": [
    "We see that both model is less accurate than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc1bf3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:58.211359Z",
     "start_time": "2021-07-18T05:05:58.062197Z"
    }
   },
   "outputs": [],
   "source": [
    "# if we add 1000% noise to our data\n",
    "X_noise, y_noise = add_noise(X, y, 10.)\n",
    "lm.fit(X_noise, y_noise), tree.fit(X_noise, y_noise)\n",
    "plt.scatter(X_noise, y_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea9c702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T05:05:58.217072Z",
     "start_time": "2021-07-18T05:05:58.213239Z"
    }
   },
   "outputs": [],
   "source": [
    "# let Xi = 6, we expect the ground truth to be 10 + 5 * 6 = 40\n",
    "_sample = [[6]]\n",
    "print(f\"Linear regression prediction: {lm.predict(_sample)}\")\n",
    "print(f\"Tree regressor prediction: {tree.predict(_sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a960d",
   "metadata": {},
   "source": [
    "We see that both models are only getting further away from the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5cdcc",
   "metadata": {},
   "source": [
    "# Closing remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711bcdd",
   "metadata": {},
   "source": [
    "We often spent most of the time on making sure our data is clean and relevant to the problem we are solving.\n",
    "\n",
    "With the help of various high level APIs, training machine learning model is often the fastest step in a project."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
